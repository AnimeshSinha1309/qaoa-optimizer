\documentclass[%
 reprint,
 amsmath,
 amssymb,
 showkeys,
 pra,
 floatfix,
]{revtex4-2}

\usepackage{xr}

\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\let\oldnl\nl% Store \nl in \oldnl
\newcommand{\nonl}{\renewcommand{\nl}{\let\nl\oldnl}}% Remove line number for one line
\usepackage{braket}
\usepackage{float}

\usepackage{graphicx}% Include figure files
\usepackage{dcolumn}% Align table columns on decimal point
\usepackage{enumitem}
\usepackage{lipsum}  
\usepackage{bm}% bold math
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=magenta
}
\usepackage{subcaption}
\captionsetup{justification = raggedright, singlelinecheck = true}
              
\begin{document}

\preprint{APS/123-QED}

\title{qLEET: Visualizing Loss Landscapes, Expressibility, Entangling power and Training Trajectories for Parameterized Quantum Circuits}

\author{Utkarsh Azad}
\email{utkarsh.azad@research.iiit.ac.in}
\author{Animesh Sinha}
\email{animesh.sinha@research.iiit.ac.in}
%   \email{laltu@iiit.ac.in}

\affiliation{%
    Center for Computational Natural Sciences and Bioinformatics, International Institute of Information Technology, Hyderabad.\\
    Center for Quantum Science and Technology,\\ International Institute of Information Technology, Hyderabad.
}%

\date{\today}% It is always \today, today,
%  but any date may be explicitly specified

\begin{abstract}

    We present qLEET, an open-source Python package for studying parameterized quantum circuits (PQCs), which are widely used in various variational quantum algorithms (VQAs) and quantum machine learning (QML) algorithms. qLEET enables computation of properties such as expressibility and entangling power of a PQC by studying its entanglement spectrum and the distribution of parameterized states produced by it. Furthermore, it allows users to visualize the training trajectories of PQCs along with high-dimensional loss landscapes generated by them for different objective functions. It supports quantum circuits and noise models built using popular quantum computing libraries such as Qiskit, Cirq, and Pyquil. In our work, we demonstrate how qLEET provides opportunities to design and improve hybrid quantum-classical algorithms by utilizing intuitive insights from the ansatz capability and structure of the loss landscape.

\end{abstract}

\keywords{Quantum Computing, Quantum Software, Parameterized Quantum Circuits, Hybrid Quantum-Classical Algorithms}
\maketitle

%\tableofcontents

\section{\label{sec:intro}Introduction}

Recent advances in the field of quantum technologies have led to the development of near-term quantum hardware, more popularly referred to as noisy intermediate-scale quantum (NISQ) devices \cite{nisq_preskill, RevModPhys.94.015004}. Unfortunately, due to restrictive qubit connectivity, imperfect qubit control, and minimal error correction, their computation capabilities are limited to executing only low depth algorithms \cite{9251243}. For this reason, these devices are supposedly used as accelerators for their classical counterparts instead of stand-alone devices themselves. This has led to the development of hybrid quantum-classical (HQC) algorithms, which use both quantum and classical hardware either iteratively or sequentially. The problems are decomposed into classically tractable and intractable parts in such a setup, where the latter is solved using the quantum processor \cite{Endo2021-zy}. 

Parameterized quantum circuits (PQCs) are one of the fundamental components of these algorithms \cite{Benedetti2019-gz}. They are responsible for evolving the qubits system to a state which is dependent on the series of parameters ($\vec{\theta}$) provided by a classical processor and the objective function from some initial state $\ket{\psi_0}$. The initial state of the qubit system here could either be ground state $\ket{0\ldots0}$, or some other particular state such as Hartree-Fock state $\ket{\psi}_{HF}$ as in the case of electronic structure problems. The PQC ($U(\vec{\theta})$) is also popularly referred to as \textit{ansatz} \cite{Benedetti2019-gz}. Their structure dramatically affects the performance of HQCs as they influence both the (i) convergence speed, i.e., the number of quantum-classical feedback iterations, and (ii) closeness of the final state ($\ket{\psi({\vec{\theta}})}$) to a state that optimally solves the problem ($\ket{\psi({\vec{\theta}^*})}$), i.e., the overlap or the fidelity ($\mathcal{F} = |\langle\psi({\vec{\theta})} | \psi({\vec{\theta}^*})\rangle|^{2}$) \cite{9781107002173} between the final state and the target state. 

Therefore, it becomes imperative to design optimal PQCs for a given problem. However, this is not straightforward because their design depends not only on the problem instances themselves but also on the quantum hardware that executes them. After all, some essential properties like depth of circuit post compilation depend on the hardware's topology and the supported native gates. Overall, there exist three main classes of ansätze: (i) problem-inspired ansatz, where the evolutions of generators derived from properties of the given system are used to construct the PQCs \cite{Romero2018-uc}, (ii) hardware-efficient ansatz, where a minimal set of quantum gates native to a given device are used to construct the PQCs \cite{Kandala2017-wn}, and (iii) adaptive ansatz, which is midway between the former two ansätze \cite{PRXQuantum.2.020310}. Using these three classes, one can develop numerous ansatz designs for any given problem. However, to finally choose one, we need to have insights from the problems and a concrete strategy to compare their performances.

\begin{figure*}[!th]
    \centering
    \includegraphics[width=0.61\linewidth]{images/qleet-architecture.pdf}
    \caption{The architecture stack for qLEET}
    \label{fig:qleet-architecture}
\end{figure*}

In this work, we present a python library called qLEET \footnote{\href{https://github.com/QLemma/qleet}{https://github.com/QLemma/qleet}}, \cite{qleet-zenodo}. The primary motivation behind the development of qLEET stems from this need to have a framework for analyzing the capabilities of parameterized quantum circuits and comparing their performances. It does so by allowing users to study various properties related to the behavior of PQCs and assess their effectiveness for a given problem instance. In particular, it will enable visualization of the loss landscape of a PQC for a given objective function and its training trajectory in the parameter space. Furthermore, it allows the calculation of some essential properties of PQCs, such as their expressibility and entangling power \cite{10.1002/qute.201900070}. It is integrable with other popular libraries such as Qiskit \cite{comp_qiskit}, Cirq \cite{comp_cirq}, or PyQuil \cite{ccquad_Pyquil} and also supports instruction-set languages like OpenQASM \cite{2021arXiv210414722C} and Quil \cite{ccquad_Pyquil}.

\textit{Structure} - In Sec. \ref{sec:overview} we present an overview of the architecture stack of qLEET. Then in Sec. \ref{sec:training} and Sec. \ref{sec:challenges}, we demonstrate the use of qLEET in the context of analyzing training of PQCs and mitigating the challenges associated with them. Finally, in Sec. \ref{sec:conclusion}, we conclude with a discussion about our current limitation and possible future extensions of this work.

\section{\label{sec:overview}Overview}

All the functionalities present in qLEET are grouped under four modules, which reside under the top-level module called \texttt{qleet}. Each such module provides modularity in feature development and interacts with one another via a specified workflow or API. We present the complete architecture stack for qLEET in Fig. \ref{fig:qleet-architecture}, listing down the following modules and identifying the interactions within them:

\begin{enumerate}

	\item \textbf{Interface module}: \texttt{qleet.interface} serves as the interface for users to build workflow of the variational computation by specifying the parameterized quantum circuit (PQC) along with its key components like symbolic placeholders for variational parameters ($\vec{\theta}$), an objective or a cost function ($\mathcal{C}$) as an observable in Pauli basis and some metrics for evolving the circuit to the final state defined by \texttt{MetricSpec}. It also contains \texttt{CircuitDescriptor}, which allows for the building of PQC using any supported framework, therefore making the computation software agnostic, and \texttt{MetaLogger}, which maintains the record for events that happen during qLEET's execution. 

	\item \textbf{Simulators module}: \texttt{qleet.simulator} contains the  simulation engine for performing the computation. Depending upon the type of workflow you want to execute, you can choose between \texttt{PQCTrainer} and \texttt{CircuitSimulator} for running training routing and for performing standalone circuit simulation, respectively. At this stage, you may also describe the simulation environment for the computation by providing a noise model for the system. 

	\item \textbf{Analyzers module}: \texttt{qleet.analyzers} performs execution of \texttt{CircuitDescriptor} object using \texttt{PQCTrainer} or \texttt{CircuitSimulator} functions present in the \texttt{qleet.simulator} module. Therefore, \texttt{qleet.analyzers} acts as a linkage between the previous two modules and is responsible for estimating various essential properties regarding PQC. These include loss landscape and training trajectory calculation or histogram prediction for variational computation and expressibility, entangling power and entanglement spectrum calculations for a given ansatz structure. This module also offers plotting functionality for some of these features.
	
	\item \textbf{Example module}: \texttt{qleet.examples} contains basic set of introductory tutorials and predefined templates for users to get started with using qLEET and contribute to it. These include examples of using \texttt{qleet.analyzers} for various kinds of calculations, as mentioned before.

\end{enumerate} 

We maintain the consistency of our codebase via unit testing, type checking, and format checker via pytest \cite{pytestx.y}, mypy \cite{mypy}, and black \cite{black}, respectively. Overall, we aim for the architecture stack for qLEET to follow object-oriented design principles, which helps us create a clean and modular software tool that is easy to test, debug, and maintain in the future. 

% \begin{figure*}[!tp]
%     \centering
%     \includegraphics[width=\linewidth]{images/loss-landscape.pdf}
%     \caption[Loss landscapes for QAOA]{Loss landscapes for solving Max-Cut problem for an Erdos-Renyi graph with $12$ nodes and $0.5$ edge probability, using QAOA for different values of $p$.}
%     \label{fig:qleet-loss}
% \end{figure*}


\section{\label{sec:features}Features}

This section presents the theory and examples for the features supported by the qLEET. We begin by introducing the idea of the trainability of a parameterized quantum circuit (PQC). From there, we would motivate the idea of studying different properties related to PQC to improve and analyze its trainability. We end the discussion in each subsection by demonstrating how modules in \texttt{qleet} can be used for analyzing the mentioned properties. 

\subsection{\label{sec:training}Trainability of PQCs}

We consider an N-qubit PQC $\hat{U}(\vec{\theta})$ with an objective function defined by a Hermitian observable $O$ in the Pauli basis. For an input quantum state $\rho$, the process of training is defined as minimizing the following function $\mathcal{C}$:
\begin{equation}
	\min \mathcal{C}(\vec{\theta}) = \min \text{Tr}[O \hat{U}(\vec{\theta}) \rho \hat{U}^{\dagger}(\vec{\theta})]
\end{equation}
A PQC $\hat{U}(\vec{\theta}$ evolves the input state $\rho$ to a parameterized target state $\rho(\vec{\theta})$ and to minimize $C(\vec{\theta})$ we update paramters $\vec{\theta}$ via some classical optimization routine such that:
\begin{equation}
	\vec{\theta}_{k+1} = \vec{\theta}_k - \gamma f(\nabla_{\vec{\theta}})\ \mathcal{C}, \quad f(\textbf{0})= 0 
\end{equation}
\begin{figure}[!tp]
    \centering
    \includegraphics[width=0.6\linewidth]{images/qaoa-graph.pdf}
    \caption[Problem graph for QAOA]{Problem graph considered for MaxCut using QAOA. It is generated as an Erdos-Renyi graph with $12$ nodes and $0.5$ edge probability.}
    \label{fig:qoao-maxcut-graph}
\end{figure}
Therefore, for successfully training a PQC, we would require contributions from any variational parameter $\theta_v$ to $\nabla_{\vec{\theta}}$, i.e., $\partial\mathcal{C}/\partial\theta_v$ to be non-vanishing, non-exploding and unbiased. This means that we expect $\mathbb{E}(\partial\mathcal{C}/\partial\theta_v) = 0$ and $\text{Var}(\partial\mathcal{C}/\partial\theta_v) > 0$  $\forall \theta_v \in \vec{\theta}$. However, this is not always the case, as we would see later in Sec. \ref{sec:challenges}. To better understand this behavior, it is critical to look at the evolution of $\mathcal{C}$ with respect to changes in variational parameters for which loss landscape and training path is beneficial. Furthermore, it has also been shown that circuits with $\nabla_{\vec{\theta}}\ \mathcal{C} \rightarrow 0$ for circuits with large expressibility. Hence, it is also crucial to not just look at the evolution of $\mathcal{C}$ but also get insights from the intrinsic properties of the PQC itself, such as its expressibility and entangling power.

\begin{figure*}[htp]
    \centering
    \begin{subfigure}[b]{0.32\linewidth}
        \includegraphics[width=\textwidth]{images/loss_landscape_p1.pdf}
        \caption{Loss Landscape for $p=1$\label{fig:loss-p1}}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\linewidth}
        \includegraphics[width=\textwidth]{images/loss_landscape_p2.pdf}
        \caption{Loss Landscape for $p=4$\label{fig:loss-p4}}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\linewidth}
        \includegraphics[width=\textwidth]{images/loss_landscape_p3.pdf}
        \caption{Loss Landscape for $p=8$\label{fig:loss-p8}}
    \end{subfigure}%
    \hfill\newline
    \begin{subfigure}[b]{0.32\linewidth}
        \includegraphics[width=\textwidth]{images/training_trajectory_p1.pdf}
        \caption{Training trajectories for $p=1$\label{fig:train-p1}}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\linewidth}
        \includegraphics[width=\textwidth]{images/training_trajectory_p2.pdf}
        \caption{Training trajectories for $p=4$\label{fig:train-p4}}
    \end{subfigure}
    \begin{subfigure}[b]{0.32\linewidth}
        \includegraphics[width=\textwidth]{images/training_trajectory_p3.pdf}
        \caption{Training trajectories for $p=8$\label{fig:train-p8}}
    \end{subfigure}%
    \caption{Loss landscape and training trajectories plots for solving the MaxCut problem using QAOA routine implemented with qLEET for the graph presented in Fig. \ref{fig:qoao-maxcut-graph}. The training trajectories have been plotted for five instances of training with different random initializations of variational parameters $\vec{\theta}$ for each value of $p\in\{1, 4, 8\}$, where $p$ denotes the number of times QAOA ansatz is repeated.}
    \label{fig:loss-land-train-traj}
\end{figure*}

\subsection{Loss Landscape}

Loss landscape is a visual representation of the loss values or the $\mathcal{C}(\vec{\theta})$ around the trainable variational parameter space of the PQC. This inspection is usually done around the optimal variational parameters $\vec{\theta}^{*}$ to identify features like local minima, ridges, and valleys present in the loss surface. Such analysis helps in analyzing smoothness off the surface, indicating the ease with which a gradient-based optimizer might be able to perform on it \citep{loss-landscapes}. 

For example, in Fig. \ref{fig:loss-land-train-traj}, we look at the loss landscape associated with solving the MaxCut problem using the QAOA algorithm \cite{2014arXiv1411.4028F} for an Erdos-Renyi graph (Fig. \ref{fig:qoao-maxcut-graph}). We see that as the number of layers of QAOA ansatz, parameterized by $p$, are increased, the loss landscape becomes much smoother, and local minima pits disappear. Therefore, it would be much easier for a descent-based optimizer to traverse to global minima in case of higher $p$. This and similar loss landscape calculations in qLEET are done using the \texttt{loss\_landscape} function present in the analyzer module. As shown in Eq. \ref{eqn:loss-landscape-plot}, we compute the value of the loss function $\mathcal{L}$ for all the parameters in an orthonormalized 2-D subspace $S$ with basis vectors $\phi_i$ sampled from the whole trainable variational parameter space. 
\begin{equation}\label{eqn:loss-landscape-plot}
    \begin{split}
        \mathcal{L}(\phi_i) 
        &= \mathcal{C}_{\text{PQC}}(\vec{\theta}^* + \vec{\phi_i}), \quad \vec{\phi_i} = \sum_i \alpha_i \theta_i\\ 
        &= \sum_{O} \text{Tr}\Bigg[O\rho \bigg(\vec{\theta}^* + \vec{\phi_i} \bigg) \Bigg]
    \end{split}
\end{equation}
We gather different information about the loss of landscape based on how we choose to perform the sampling. For example, using principal component analysis (PCA) over the set of variational parameters $\vec{\theta}$ at each training step would give us the vectors $\vec{\phi}$ that represent the directions in parameter space for which major changes happen during that training step. Similarly, other methods for obtaining subspace could be used, such as doing random sampling of basis vectors or t-SNE (t-Distributed Stochastic Neighbor Embedding) of the parameter vectors encountered in the training trajectory. All such methods provide beneficial insights about the structure of the loss landscape using which one could adapt their training strategy by tweaking the optimization routine, evaluation metric, etc. 

\subsection{Training Trajectory}

In many cases, just looking at the loss landscape for a given PQC model is not enough as we define the subspace $S$ using two of many possible directions as axes by taking linear combinations of variational parameters, while the loss landscape itself is highly nonlinear. Moreover, the high dimensionality of the parameter space makes the task of visualization of loss landscape extremely challenging. However, both of these difficulties can somewhat be alleviated by visualizing the loss landscape via the evolution of variational parameters of PQC during training in low dimensions. This evolution of variational parameters can be realized as the training trajectory for the PQC, and plotting them over several re-initializations helps us learn about the convergence properties of the PQCs and their optimization schedules. 

\begin{figure*}[!tp]
    \centering
    \includegraphics[width=0.82\textwidth]{images/expressibility.pdf}
    \caption[Quantifying expressibility for single-qubit circuits]{Quantifying expressibility for single-qubit circuits. For each of the four circuits show here, 1000 sample pairs of circuit parameter vectors were uniformly drawn, corresponding to 2000 parameterized states. Histograms of estimated fidelities (orange) are shown, overlaid with fidelities of the Haar-distributed ensemble (blue), with the computed Kullback-Leibler (KL) divergence and Jensen-Shannon Distance (JSD) reported above the histograms.}
    \label{fig:expressibility}
\end{figure*}

In qLEET, training trajectories are calculated inside the analyzer module by the \texttt{training\_path} function. We use the entire set of variational parameters $\vec{\theta}^{t}$ to generate the trajectory over all re-initialization for every time step $t$ in the training process. We project the parameter vectors down to an orthonormalized 2-D subspace $S$ using techniques such as PCA, t-SNE, or PHATE. Similar to the case of loss landscape visualization, each of the mentioned techniques reveals different trajectory characteristics depending on its ability to preserve both global and local structures of higher-dimensional data in low dimensional subspace. Furthermore, the 2-D projections of the parameter trajectories can also be plotted on the loss surface, with the loss values as its third axis \citep{training-trajectories}.

For example, we present the training trajectories with t-SNE projection in Fig. \ref{fig:loss-land-train-traj} for the same MaxCut problem that we discuss in the previous subsection about the loss landscape. We look at five different training instances for each $p$, where we begin with randomized initialization of variational parameters $\vec{\theta}$ every time. We see that for $p=1$ evolutions of $\vec{\theta}$ for every instance happen in their own respective clusters, suggesting the optimizer unsuccessfully gets stuck for different local minima every time. In contrast, for both $p=4$ and $p=8$, we see much lesser clusters formation and more intercrossing, hinting at certain parameters $\theta_k$ evolving to the same values while the optimizer reaches the global minima. 

% \begin{figure}[!tp]
%     \centering
%     \includegraphics[width=\linewidth]{images/training-trajectories.pdf}
%     \caption[Parameters in from several Training Trajectories]{This shows a 2-D projection of the parameter vectors plotted on the X-Y axes for 5 different re-initializations, each shown using a different color. These are collected over the entire optimization run and the final value of each run is plotted with a larger blob, visible at the top of each trajectory. The z-axis shows the loss value at that parameter vector. In this plot, it is visible that the trajectories do not mix and instead ascend up their own local optima, which indicates that sufficient exploration of the loss landscape was not performed and the optimization was very much local in nature and vary over different runs.}
%     \label{fig:expressibility}
% \end{figure}

\subsection{Expressibility}

We generate a distribution of state $\rho(\vec{\theta})$ for a PQC $\hat{U}(\vec{\theta})$ by randomly sampling over the variational parameter space. We quantify the deviation of this distribution from the one obtained from the maximally expressive Haar distribution as the \textit{Expressibility} of the given ansatz.
\begin{equation}\label{qleet:eq3}
    A^{(t)} =\left\Vert \int_\text{Haar}\rho^{\otimes t} \text{d}\rho - \int_{\vec{\theta}}\rho(\vec{\theta})^{\otimes t} \text{d}\rho(\vec{\theta}) \right\Vert_\text{HS}^2\,
\end{equation}
where $\int_\text{Haar}\text{d}\rho$ denotes the integration over the states $\rho$ distributed according to the Haar measure, $t$ represent the $t^{\text{th}}$ moment,  and $\left\Vert A \right\Vert_\text{HS}^2$ is the Hilbert-Schmidt norm calculated as $\text{Tr}(A^\dagger A)$. We compute Eq. \ref{qleet:eq3} as the divergence between the state fidelities generated from the ensemble of uniformly sampled parameterized states $\rho(\vec{\theta})$ to that of the ensemble obtained from uniform Haar distribution \cite{10.1002/qute.201900070}.
\begin{equation}
    \text{Expr} = D(\hat{P}_{PQC}(F; \vec{\theta}) | P_{Haar}(F))
\end{equation}
According to this definition, a PQC $U(\vec{\theta})$ is more expressible if the distribution of state fidelities generated by the ansatz circuit $U(\vec{\theta})$ is closer to the one generated by the Haar measure. Therefore, the smaller the \textit{Expr} value, the more is the expressibility of the parameterized unitary. We see this in  Fig. \ref{fig:expressibility}, where we compare the fidelity distribution of PQC and Haar random states with respect to the number of Pauli rotation gates present in the single-qubit circuits and calculate the \textit{Expr} values for both Kullback-Leibler (KL) and Jensen-Shannon (JS) divergence. Furthermore, in Fig. \ref{fig:expressibility-measure}, we measure the increasing expressibility of the five qubit ansatz $U(\vec{\theta}) =  \prod_{1}^{L}\big(\bigotimes_{i=1}^{5}R_x(\theta_i^1)R_z(\theta_i^2)R_x(\theta_i^3) \ldots \bigotimes_{i<j}CX(i, j)\big)$, where we see how expressibility increases with the number of layers $L$.  Finally, we note that, in addition to experiments like these, \texttt{expressibility} function in qLEET can also be used to predict the likelihood of whether the given PQC would be able to represent an unknown N-qubit target state and do a comparative analysis between different ansätze.

\begin{figure}[!t]
    \centering
    \includegraphics[width=\linewidth]{images/expressibility-measure.pdf}
    \caption[Visualizing entanglement spectrum for parameterized quantum circuits]{Measuring expressibility for the parameterized quantum circuit $U(\vec{\theta}) =  \prod_{1}^{L}\big(\bigotimes_{i=1}^{5}R_x(\theta_i^1)R_z(\theta_i^2)R_x(\theta_i^3) \ldots \bigotimes_{i<j}CX(i, j)\big)$ using the Jensen-Shannon distance (JSD) measure as a function of number of layers $L$. }
    \label{fig:expressibility-measure}
\end{figure}

\subsection{Entangling Capability}

A fundamental property that makes quantum computation different from the classical one is the existence of entanglement in the system, which can be potentially exploited to gain a computational advantage. Hence, it is essential to quantify its ability to generate entanglement in the system to assess the effectiveness of a parameterized quantum circuit. We use entanglement measures to capture different properties of multipartite entanglement present in the system. The first measure that we use is the Meyer-Wallach $Q$ measure \cite{10.1002/qute.201900070, doi:10.1063/1.1497700} in which the amount of entangled states produced by a PQC is estimated by measuring the average entanglement between individual qubits and the rest of the system. In this context, the entangling capability of a PQC can be defined directly via the considered entanglement measure $Q$ averaged over all states $\rho(
\vec{\theta})$ generated by the PQC from the uniform sampling of variational parameters $\vec{\theta}$:

\begin{equation}
	Q = \frac{2}{|\vec{\theta}|}\sum_{\theta_{i}\in \vec{\theta}}\Bigg(1-\frac{1}{n}\sum_{k=1}^{n}\text{Tr}(\rho_{k}^{2}(\theta_{i}))\Bigg),
\end{equation}
where $\rho_k$ is the density matrix for the state of the $k$-th qubit. In a similar spirit, we can use another entanglement measure called Scott Measure \cite{10.1007/s11128-007-0052-7}, which generalizes the Meyer-Wallach measure using $m$ entanglement measures, each of which will measure the average entanglement between blocks of $m$ qubits and the rest of the system. Therefore, as pointed out before, each measure would give access to different properties related to multipartite entanglement, and as $m$ increases, $Q_m$ becomes more sensitive to correlations of an increasingly global nature. Similar to the previous case, the entangling capability of the PQC can be defined by the value of $Q_m$ measures, averaged over uniformly sampled $\vec{\theta}$ too:
\begin{equation}
    \begin{split}
        Q_{m} &= \frac{2^{m}}{(2^{m}-1) |\vec{\theta}|}\sum_{\theta_i \in \vec{\theta}} \bigg(1 - \\ 
        & \quad \quad \frac{m! (n-m)!)}{n!}\sum_{|S|=m} \text{Tr} (\rho_{S}^2 (\theta_i)) \bigg) \\
        m &= 1, \ldots, \lfloor n/2 \rfloor
    \end{split}
\end{equation}
\begin{figure}[!t]
    \centering
    \includegraphics[width=\linewidth]{images/entanglement-capability.pdf}
    \caption[Visualizing entanglement spectrum for parameterized quantum circuits]{Measuring entangling power for the parameterized quantum circuit $U(\theta)$ using the Mayer-Wallach measure as a function of number of CNOT gates appended to the circuit $U(\vec{\theta}) = \bigotimes_{i=1}^{5}R_x(\theta_i^1)R_z(\theta_i^2)R_x(\theta_i^3)$.}
    \label{fig:entanglement-capability}
\end{figure}
In qLEET, we perform these calculations inside the $\texttt{entanglement}$ function in the analyzer module, where one can choose between both Meyer-Wallach and Scott measures for any PQC loaded as a $\texttt{CircuitDescriptor}$ object. For example, in Fig. \ref{fig:entanglement-capability}, we use it to plot the entangling capability of a five qubit circuit template $U(\vec{\theta}) = \bigotimes_{i=1}^{5}R_x(\theta_i^1)R_z(\theta_i^2)R_x(\theta_i^3)$ against the numbers of CNOT gates appended to circuit in a pair-wise fasion, i.e., CNOT$(i, j)$, where $i < j$ and $i,j <5$. We see that as the number of CNOT gates are increased, the entangling capability improves. We also notice a region of minimal increase between $[5, 7]$, which can be attributed to addition on qubits which were already transitive correlated.

\subsection{Entanglement Spectrum}

In the previous subsection, we quantified the entangling capability of an ansatz using entanglement measures. However, these measures might be insufficient to fully characterize all the properties related to multipartite entanglement \cite{PhysRevLett.115.267206}. This problem can be tackled by making use of the entanglement spectrum  \cite{PRXQuantum.1.020319}, which is defined as the eigenspectrum of the entanglement Hamiltonian $H_{\text{ent}}$:

\begin{equation}
    H_{\text{ent}} = -\log (\rho_A),
\end{equation}

where the $\rho_A = \text{Tr}_B(\rho)$ is the reduced density matrix of the qubit system obtained by the typical bipartition of the $N$ qubit system into subsystems $A$ and $B$ with $k = \lceil N/2 \rceil$ and $N-k$ qubits, respectively. For states sampled from maximally expressive Haar distribution, the eigenvalues $\xi_k$ of $H_{\text{ent}}$ follows the Marchenko-Pastur (MP) distribution \cite{10.1088/1751-8113/40/3/f04}. Therefore, we can quantify both expressibility and entangling power of the PQC by looking at the eigenspectrum of $H_{\text{ent}}^{\text{PQC}}$, calculated from uniformly sampled variational parameters $\vec{\theta}$. 

In qLEET, \texttt{entanglement\_spectrum} function in the analyzers module can be used for computing and plotting the entanglement spectrum for any given PQC $U(\vec{\theta})$. For example, in Fig. \ref{fig:entanglement-spectrum}, we use it to perform the entanglement spectrum analysis on a 16 qubit PQC, which is made of $L$ layers comprising three rotation gates on each qubit and CNOT gates between adjacent qubits, i.e., $U(\vec{\theta}) = \prod_{l}^{L}\big(\bigotimes_{i=0}^{15}R_x(\theta_i^1)R_z(\theta_i^2)R_x(\theta_i^3)\bigotimes_{i=0}^{14}CX(i, i+1)\big)$. We see that as the number of layers are increased in the ansatz, the eigenvalue distribution becomes more and more closer to the MP distribution. In fact, computing a divergence measure between these two distributions can also be used as a quantification of capability of the ansatz. 

\begin{figure}[!t]
    \centering
    \includegraphics[width=\linewidth]{images/entanglement-spectrum.pdf}
    \caption[Visualizing entanglement spectrum for parameterized quantum circuits]{Visualizing entanglement spectrum for a PQC $U(\vec{\theta}) = \prod_{1}^{L}\big(\bigotimes_{i=1}^{12}R_x(\theta_i^1)R_z(\theta_i^2)R_x(\theta_i^3) \ldots \bigotimes_{i=1}^{11}CX(i, i+1)\big)$. Here, $\xi_k$ are the eigenvalues of $H_{\text{ent}}^{U(\vec{\theta})}$ arranged in descending order and cut off at $-30$. The solid lines (blue to brown) represents the distribution $\xi_k$ for different layers $L$ and the dotted line (black) represents the ideal Marchenko-Pastur (MP) distribution. We see that as the number of layers is increased, the distribution of $\xi_k$ becomes more similar to MP distribution.}
    \label{fig:entanglement-spectrum}
\end{figure}


\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{images/barren-plateau.pdf}
    \caption[Presence of barren plateaus in parameterized quantum circuits]{Here we show the emergence of barren plateaus in the task of learning an Identity gate using the ansatz $R_X(0,\theta_1)R_X(1, \theta_2)CZ(0, 1)$ solely based on the choice of the cost function. Figures (a) and (b) represents the loss landscape for the $\mathcal{C}_{Global}$ and local $\mathcal{C}_{Local}$ cost functions, respectively. Similarly, figures (c) and (d) represents coloured heat maps for their  corresponding gradients $\nabla_{\theta}\mathcal{C}_{\text{Global}}$ and $\nabla_{\theta}\mathcal{C}_{\text{Local}}$. We see that for $\mathcal{C}_{Global}$, the gradients vanish rapidly towards the boundaries of the loss landscape.}
    \label{fig:barren-plateau}
\end{figure}


\subsection{Parameter Histograms}

For our $M$-parameter PQC $\hat{U}(\vec{\theta})$, the parameters $\theta_i$ at the start of the training process are sampled from some prior probability distribution $\pi_0(\theta)$. Through the training process, we desire to learn an optimized join probability distribution over the parameters $\pi^*(\theta)$. This learnt parameter distribution
\begin{equation}
    \pi^* = \underset{\pi(\theta)}{\operatorname{argmin}} \; \underset{\theta \sim \pi}{\mathbb{E}} \mathcal{C}(\vec{\theta}) = \underset{\pi(\theta)}{\operatorname{argmin}} \; \underset{\theta \sim \pi}{\mathbb{E}} Tr[O \hat{U}(\vec{\theta}) \rho \hat{U}^\dagger(\vec{\theta})]
\end{equation}

The evolution of the parameter distribution from $\pi_0 \rightarrow \pi_t \rightarrow \pi^*$ is visualized by our parameter histogram module. The probability distributions are analyzed by starting with an ensemble of vectors $\vec{\theta_l} \sim \pi_0$, letting the entire ensemble evolve using our classical optimization subroutine, and sampling the vectors in the ensemble to get the distribution over parameters at time $t$ as $\pi_t(\vec{\theta})$. 

The marginal distribution over each variable $\pi_t(\vec{\theta_i})$ is plotted at each timestep. Change in the profile of this distribution over consecutive timesteps implies a role of those parameters in those timesteps of the learning process.


\section{\label{sec:challenges}Challenges}

In this section, we will discuss some key challenges that we come across in variational quantum computation and possible ways to identify and mitigate these problems by using tools provided in qLEET.

\subsection{Effect of Noise}

The quantum hardware that exists today are imperfect, as a result of which a computation being run on them may suffer various kinds of errors \cite{Chaudhary2022-kl}. Therefore, in order to realistically simulate and characterize the performance of a parameterized quantum circuit (PQC), we must include these errors in our computation. Our library does so by using noise models from libraries such as Cirq and Qiskit, which provides for errors related to coherent gate errors, incoherent errors, and state preparation and measurement (SPAM) errors. Users can provide the \texttt{NoiseModel} to the \texttt{CircuitSimulator} function in the simulator module while running the experiments. 

Another source of error in the quantum computation arises from the limited number of times the circuit is repeatedly executed for sampling. This restricts the precision with which one can compute the Pauli observable $\hat{O}$ for calculating the cost function $\mathcal{C}$ as the number of measurements $m$ required for estimating the expectation value $\langle\hat{O}\rangle$ with precision $\epsilon$ would be $O(1/\epsilon^2)$. In qLEET, the default value of the number of repetitions is $1024$ and is determined by the \texttt{shots} variable, which can be provided at the time of calling any analysis function from the analyzer module.


\subsection{Presence of Barren Plateaus}

The main crux of the discussion presented in the previous section is that the choice of ansatz and the cost function together is crucial for successfully training a PQC for a given task. One of the critical hindrances for the training to go as expected is the barren plateau (BP) phenomenon, where the partial derivatives $\partial_{\theta_k}\mathcal{C}(\vec{\theta})$ of the cost function $\mathcal{C}(\vec{\theta})$ with respect to variational parameters $\theta_k$ will, on average, exponentially vanish (Eq. \ref{eq:barren-plateau}). This leads to the flattening of the loss landscape, traversing through, which would require an exponentially large number of shots (for more precision) against finite sampling noise to determine the direction that minimizes the cost. Moreover, it was recently shown in \cite{2020arXiv200714384W} that BPs can also be induced due to noise present in the quantum hardware. This could be a significant issue since it could erase the potential computation advantage associated with quantum computation due to the exponential scaling required to attain the necessary precision, making the complexity comparable to classical algorithms.

\begin{equation}\label{eq:barren-plateau}
	\text{Var}_{\vec{\theta}}[\partial_{\theta_k}\mathcal{C}(\vec{\theta})] \in O\left(\frac{1}{m^N}\right),\quad \text{for}\ m > 1
\end{equation}

In qLEET, one can potentially visualize the BP phenomena by visualizing the loss landscape for a chosen PQC and cost function. This could allow users to see if BP can be mitigated by tweaking either the structure of PQC itself or just the cost function. For example, in Fig. \ref{fig:barren-plateau}, we show an example of BP dependent on the cost function in a shallow ansatz \cite{s41467-021-21728-w}. Here we compare global $\mathcal{C}_{\text{Global}}$ and local $\mathcal{C}_{\text{Local}}$ cost functions for learning the Identity gate using a very simple ansatz: $R_X(0,\theta_1)R_X(1, \theta_2)CZ(0, 1)$. 
\begin{equation}
\begin{split}
    \mathcal{C}_{\text{Global}} &= \bra{\psi(\vec{\theta})} (I - \ket{0\ldots0}\bra{0\ldots0}) \ket{\psi(\vec{\theta})} \\
    &= 1 - p_{0\ldots0}
\end{split}
\end{equation}
\begin{equation}
\begin{split}
    \mathcal{C}_{\text{Local}} &= \bra{\psi(\vec{\theta})} \Bigg(I - \frac{1}{n}\sum_j \ket{0}\bra{0}_j\Bigg) \ket{\psi(\vec{\theta})} \\
    &= 1 - \frac{1}{n}\sum_j p_{0_j}
\end{split}
\end{equation}
We see how the loss landscape flattens for the $\mathcal{C}_{\text{Global}}$ and the gradients vanish exponentially in comparison to  $\mathcal{C}_{\text{Local}}$. In addition to the BP phenomena, we also notice the narrow gorge phenomena, where global minima are contained in a steeply deep valley. This makes it difficult for gradient-based optimization to reach the global minima since it might not have a low learning rate to not overstep inside the gorge. 

\subsection{Estimation of Reachability}

Reachability quantifies whether a given PQC, $\hat{U}(\vec{\theta})$, with parameters $\vec{\theta}$ is capable of representing a parameterized quantum state $\ket{\psi(\vec{\theta})}$ that minimizes the cost function $\mathcal{C}$. Mathematically it is defined as \cite{PhysRevLett.124.090504}:
\begin{equation}
f_\text{R}=\text{min}_{\psi\in\mathcal{H}}\bra{\psi}\mathcal{C}\ket{\psi}-\text{min}_{\vec{\theta}}\bra{\psi(\vec{\theta})}\mathcal{C}\ket{\psi(\vec{\theta})},
\end{equation}
where the first and second term is the minimum over all states $\ket{\psi}$ sampled from the Haar measure and all states that the PQC can represent, respectively. The reachability is equal or greater than zero $f_\text{R}\ge0$, with $f_\text{R}=0$ when the PQC can generate an optimal state $\ket{\psi(\vec{\theta}^*)}$ that minimizes the objective function. This can be easily implemented in qLEET using the \texttt{CircuitSimulator} function present in the simulator module.  

\section{\label{sec:conclusion}Conclusion}

This paper presents an open-source library called qLEET and demonstrates its ability to analyze various properties of parameterized quantum circuits (PQCs), such as their expressibility and entangling power. We motivate the importance of studying these properties from the problem of trainability of PQCs. We have discussed and showed how important insights could be gained from visualizing loss landscapes and training trajectories for variational quantum computation. We also present the theory of expressibility and entangling capability of a PQC based on the deviation of the distribution of parameterized states produced from the Haar measure, which samples uniformly from the entire Hilbert space. We also describe the idea of the entanglement spectrum, which allows visualizing the previous two properties at once. Overall, we demonstrate how different modules included in \texttt{qleet} can be used by users to study various variational algorithms and quantum machine learning models. Finally, we discuss some critical challenges for variational quantum algorithms such as Barren Plateaus and Reachability. We conclude that qLEET will provide opportunities for the quantum community to design new hybrid algorithms by utilizing intuitive insights from the ansatz capability and structure of the loss landscape.

\section*{Acknowledgements}
We acknowledge the help and financial support of the Unitary Fund for this project. We also acknowledge Prof. Harjinder Singh for the fruitful discussions we had with him throughout the development of this library.


\bibliographystyle{apsrev4-2}
%\bibliographystyle{unsrt}


\bibliography{qleet}% Produces the bibliography via BibTeX.


\end{document}
%
% ****** End of file apssamp.tex ******
